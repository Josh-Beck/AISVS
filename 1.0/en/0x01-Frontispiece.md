# Frontispiece

## About the Standard  

The **Artificial Intelligence Security Verification Standard (AISVS)** is a community‑driven catalogue of security requirements that data scientists, MLOps engineers, software architects, developers, testers, security professionals, tool vendors, regulators, and consumers can use to design, build, test, and verify **trustworthy AI‑enabled systems and applications**. It provides a common language for specifying security controls across the AI lifecycle—from data collection and model development to deployment and ongoing monitoring—so that organizations can measure and improve the resilience, privacy, and safety of their AI solutions.

## Copyright and License  

Version 0.1 (First Public Draft), 2025  

![license](../images/license.png)

Copyright © 2025 The AISVS Project.  

Released under the [Creative Commons Attribution‑ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).  
For any reuse or distribution, you must clearly communicate the license terms of this work to others.

## Project Leads  

|                         |                             |
|-------------------------|-----------------------------|
| **Jim Manico**          | **Aras “Russ” Memisyazici** |

## Working Group  

*To be announced. If you would like to contribute, please open an issue or pull request in the AISVS repository.*

## Other Contributors and Reviewers  

*To be announced. If you would like to contribute, please open an issue or pull request in the AISVS repository.*

---

**AISVS** is a brand‑new standard created specifically to address the unique security challenges of artificial‑intelligence systems. While it draws inspiration from broader security best practices, every requirement in AISVS has been developed from the ground up to reflect the AI threat landscape and to help organizations build safer, more resilient AI solutions.
